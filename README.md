# awsome-continue-pretraining

## Continual Pre-Training of Large Language Models: How to (re)warm your model?
https://arxiv.org/pdf/2308.04014


## Continual Learning for Large Language Models: A Survey
https://arxiv.org/pdf/2402.01364v2

<img width="1032" alt="image" src="https://github.com/llama-cpt/awsome-continue-pretraining/assets/10681979/cc2fc67e-18aa-419b-be85-e9c3b1ddc1c9">


EMNLP'22 Temporalwiki: A lifelong benchmark for training and evaluating ever-evolving language models.

ICLR'22 Towards continual knowledge learning of language models

ICLR'23 Continual pretraining of language models. 

CoRR'22 Continual pre-training mitigates forgetting in language and vision.

ACL'23Finding Recyclable tuning for continual pre-training.

'24 Pllama: An open-source large language model for plant science

'23 Efficient continual pre-training for building domain specific large language models

Ecomgpt-ct: Continual pre-training of e-commerce large language models with semi-structured data

ACL'21 Learning to solve NLP tasks in an incremental number of languages.

'23 A study of continual learning under language shift.

IJCAI'22 CERT: continual pre-training on sketches for library oriented code generation

ACL'23 Exploring continual learning for code generation models

